{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson A3: Concurrency & Async Programming\n",
    "\n",
    "**Duration**: 150-165 minutes  \n",
    "**Stage**: Advanced (Mastery)  \n",
    "**Prerequisites**: Lessons A1-A2 (Lifetimes, Smart Pointers)\n",
    "\n",
    "---\n",
    "\n",
    "## üìã What You'll Learn\n",
    "\n",
    "This lesson covers Rust's powerful concurrency features, from threads and message passing to async/await and futures. You'll learn to write safe, efficient concurrent code that leverages Rust's type system to prevent data races at compile time.\n",
    "\n",
    "**Why this matters**: Concurrency is essential for modern applications - from web servers handling thousands of connections to data processing pipelines. Rust's fearless concurrency makes it possible to write concurrent code that's both fast and safe, without the bugs that plague concurrent code in other languages.\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this lesson, you will be able to:\n",
    "1. Create and manage threads safely\n",
    "2. Use channels for message passing\n",
    "3. Implement shared-state concurrency with Arc/Mutex\n",
    "4. Understand async/await syntax\n",
    "5. Work with Futures and executors\n",
    "6. Build concurrent applications with Tokio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "// Basic thread creation and management\n",
    "\n",
    "use std::thread;\n",
    "use std::time::Duration;\n",
    "\n",
    "fn basic_threads_demo() {\n",
    "    println!(\"=== Basic Thread Creation ===\");\n",
    "    \n",
    "    // Spawn a simple thread\n",
    "    let handle = thread::spawn(|| {\n",
    "        for i in 1..=5 {\n",
    "            println!(\"Thread: count {}\", i);\n",
    "            thread::sleep(Duration::from_millis(100));\n",
    "        }\n",
    "    });\n",
    "    \n",
    "    // Main thread work\n",
    "    for i in 1..=3 {\n",
    "        println!(\"Main: count {}\", i);\n",
    "        thread::sleep(Duration::from_millis(150));\n",
    "    }\n",
    "    \n",
    "    // Wait for thread to complete\n",
    "    handle.join().unwrap();\n",
    "    println!(\"Thread completed!\\n\");\n",
    "    \n",
    "    // Multiple threads\n",
    "    let mut handles = vec![];\n",
    "    \n",
    "    for i in 0..3 {\n",
    "        let handle = thread::spawn(move || {\n",
    "            println!(\"Worker thread {} starting\", i);\n",
    "            thread::sleep(Duration::from_millis(100 * (i + 1) as u64));\n",
    "            println!(\"Worker thread {} finished\", i);\n",
    "            i * i // Return value\n",
    "        });\n",
    "        handles.push(handle);\n",
    "    }\n",
    "    \n",
    "    // Collect results\n",
    "    let results: Vec<i32> = handles\n",
    "        .into_iter()\n",
    "        .map(|handle| handle.join().unwrap())\n",
    "        .collect();\n",
    "    \n",
    "    println!(\"Thread results: {:?}\", results);\n",
    "}\n",
    "\n",
    "basic_threads_demo();"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message Passing with Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "// Message passing with channels\n",
    "\n",
    "use std::sync::mpsc;\n",
    "use std::thread;\n",
    "use std::time::Duration;\n",
    "\n",
    "#[derive(Debug, Clone)]\n",
    "enum Message {\n",
    "    Text(String),\n",
    "    Number(i32),\n",
    "    Quit,\n",
    "}\n",
    "\n",
    "fn channels_demo() {\n",
    "    println!(\"\\n=== Message Passing with Channels ===\");\n",
    "    \n",
    "    // Simple channel example\n",
    "    let (tx, rx) = mpsc::channel();\n",
    "    \n",
    "    thread::spawn(move || {\n",
    "        let messages = vec![\n",
    "            \"Hello\",\n",
    "            \"from\", \n",
    "            \"the\",\n",
    "            \"thread\"\n",
    "        ];\n",
    "        \n",
    "        for msg in messages {\n",
    "            tx.send(msg.to_string()).unwrap();\n",
    "            thread::sleep(Duration::from_millis(100));\n",
    "        }\n",
    "    });\n",
    "    \n",
    "    // Receive messages\n",
    "    for received in rx {\n",
    "        println!(\"Received: {}\", received);\n",
    "    }\n",
    "    \n",
    "    // Multiple producers\n",
    "    let (tx, rx) = mpsc::channel();\n",
    "    \n",
    "    for i in 0..3 {\n",
    "        let tx_clone = tx.clone();\n",
    "        thread::spawn(move || {\n",
    "            for j in 0..3 {\n",
    "                let msg = Message::Text(format!(\"Producer {} - Message {}\", i, j));\n",
    "                tx_clone.send(msg).unwrap();\n",
    "                thread::sleep(Duration::from_millis(50));\n",
    "            }\n",
    "            tx_clone.send(Message::Number(i * 10)).unwrap();\n",
    "        });\n",
    "    }\n",
    "    \n",
    "    // Drop original sender\n",
    "    drop(tx);\n",
    "    \n",
    "    println!(\"\\nMultiple producers:\");\n",
    "    for received in rx {\n",
    "        match received {\n",
    "            Message::Text(text) => println!(\"Text: {}\", text),\n",
    "            Message::Number(num) => println!(\"Number: {}\", num),\n",
    "            Message::Quit => break,\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "channels_demo();"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shared State with Arc and Mutex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "// Shared state with Arc<Mutex<T>>\n",
    "\n",
    "use std::sync::{Arc, Mutex};\n",
    "use std::thread;\n",
    "use std::time::Duration;\n",
    "\n",
    "#[derive(Debug)]\n",
    "struct Counter {\n",
    "    value: i32,\n",
    "    name: String,\n",
    "}\n",
    "\n",
    "impl Counter {\n",
    "    fn new(name: String) -> Self {\n",
    "        Counter { value: 0, name }\n",
    "    }\n",
    "    \n",
    "    fn increment(&mut self) {\n",
    "        self.value += 1;\n",
    "        println!(\"{}: incremented to {}\", self.name, self.value);\n",
    "    }\n",
    "    \n",
    "    fn get_value(&self) -> i32 {\n",
    "        self.value\n",
    "    }\n",
    "}\n",
    "\n",
    "fn shared_state_demo() {\n",
    "    println!(\"\\n=== Shared State with Arc<Mutex<T>> ===\");\n",
    "    \n",
    "    // Simple shared counter\n",
    "    let counter = Arc::new(Mutex::new(0));\n",
    "    let mut handles = vec![];\n",
    "    \n",
    "    for i in 0..5 {\n",
    "        let counter_clone = Arc::clone(&counter);\n",
    "        let handle = thread::spawn(move || {\n",
    "            for j in 0..3 {\n",
    "                let mut num = counter_clone.lock().unwrap();\n",
    "                *num += 1;\n",
    "                println!(\"Thread {} increment {}: value = {}\", i, j, *num);\n",
    "                // Lock is automatically released when `num` goes out of scope\n",
    "            }\n",
    "        });\n",
    "        handles.push(handle);\n",
    "    }\n",
    "    \n",
    "    for handle in handles {\n",
    "        handle.join().unwrap();\n",
    "    }\n",
    "    \n",
    "    println!(\"Final counter value: {}\", *counter.lock().unwrap());\n",
    "    \n",
    "    // Complex shared state\n",
    "    let shared_counter = Arc::new(Mutex::new(Counter::new(\"Shared\".to_string())));\n",
    "    let mut handles = vec![];\n",
    "    \n",
    "    for i in 0..3 {\n",
    "        let counter_clone = Arc::clone(&shared_counter);\n",
    "        let handle = thread::spawn(move || {\n",
    "            for _ in 0..2 {\n",
    "                {\n",
    "                    let mut counter = counter_clone.lock().unwrap();\n",
    "                    counter.increment();\n",
    "                } // Lock released here\n",
    "                thread::sleep(Duration::from_millis(10));\n",
    "            }\n",
    "        });\n",
    "        handles.push(handle);\n",
    "    }\n",
    "    \n",
    "    for handle in handles {\n",
    "        handle.join().unwrap();\n",
    "    }\n",
    "    \n",
    "    let final_value = shared_counter.lock().unwrap().get_value();\n",
    "    println!(\"\\nFinal shared counter value: {}\", final_value);\n",
    "}\n",
    "\n",
    "shared_state_demo();"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "// TODO: Complete the concurrent web scraper\n",
    "\n",
    "use std::sync::{Arc, Mutex, mpsc};\n",
    "use std::thread;\n",
    "use std::time::Duration;\n",
    "use std::collections::HashMap;\n",
    "\n",
    "#[derive(Debug, Clone)]\n",
    "struct WebPage {\n",
    "    url: String,\n",
    "    content: String,\n",
    "    word_count: usize,\n",
    "    load_time_ms: u64,\n",
    "}\n",
    "\n",
    "impl WebPage {\n",
    "    fn new(url: String) -> Self {\n",
    "        // Simulate web scraping\n",
    "        let load_time = (url.len() as u64 * 10) + 50; // Simulate variable load times\n",
    "        thread::sleep(Duration::from_millis(load_time));\n",
    "        \n",
    "        let content = format!(\"Content from {} with some sample text data\", url);\n",
    "        let word_count = content.split_whitespace().count();\n",
    "        \n",
    "        WebPage {\n",
    "            url,\n",
    "            content,\n",
    "            word_count,\n",
    "            load_time_ms: load_time,\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "#[derive(Debug)]\n",
    "enum WorkerMessage {\n",
    "    Scrape(String),\n",
    "    Shutdown,\n",
    "}\n",
    "\n",
    "#[derive(Debug)]\n",
    "enum ResultMessage {\n",
    "    Success(WebPage),\n",
    "    Error(String, String), // URL, Error message\n",
    "    WorkerFinished(usize), // Worker ID\n",
    "}\n",
    "\n",
    "struct WebScraper {\n",
    "    worker_count: usize,\n",
    "    results: Arc<Mutex<Vec<WebPage>>>,\n",
    "    errors: Arc<Mutex<Vec<(String, String)>>>,\n",
    "    stats: Arc<Mutex<HashMap<String, usize>>>,\n",
    "}\n",
    "\n",
    "impl WebScraper {\n",
    "    fn new(worker_count: usize) -> Self {\n",
    "        WebScraper {\n",
    "            worker_count,\n",
    "            results: Arc::new(Mutex::new(Vec::new())),\n",
    "            errors: Arc::new(Mutex::new(Vec::new())),\n",
    "            stats: Arc::new(Mutex::new(HashMap::new())),\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    fn scrape_urls(&self, urls: Vec<String>) {\n",
    "        let (work_tx, work_rx) = mpsc::channel();\n",
    "        let (result_tx, result_rx) = mpsc::channel();\n",
    "        \n",
    "        // Shared work receiver\n",
    "        let work_rx = Arc::new(Mutex::new(work_rx));\n",
    "        \n",
    "        // Spawn worker threads\n",
    "        let mut worker_handles = vec![];\n",
    "        \n",
    "        for worker_id in 0..self.worker_count {\n",
    "            let work_rx_clone = Arc::clone(&work_rx);\n",
    "            let result_tx_clone = result_tx.clone();\n",
    "            \n",
    "            let handle = thread::spawn(move || {\n",
    "                println!(\"Worker {} started\", worker_id);\n",
    "                \n",
    "                loop {\n",
    "                    let message = {\n",
    "                        let receiver = work_rx_clone.lock().unwrap();\n",
    "                        receiver.recv()\n",
    "                    };\n",
    "                    \n",
    "                    match message {\n",
    "                        Ok(WorkerMessage::Scrape(url)) => {\n",
    "                            println!(\"Worker {} scraping: {}\", worker_id, url);\n",
    "                            \n",
    "                            // Simulate potential errors\n",
    "                            if url.contains(\"error\") {\n",
    "                                let error_msg = format!(\"Failed to scrape {}\", url);\n",
    "                                result_tx_clone.send(ResultMessage::Error(url, error_msg)).unwrap();\n",
    "                            } else {\n",
    "                                let page = WebPage::new(url);\n",
    "                                result_tx_clone.send(ResultMessage::Success(page)).unwrap();\n",
    "                            }\n",
    "                        }\n",
    "                        Ok(WorkerMessage::Shutdown) => {\n",
    "                            println!(\"Worker {} shutting down\", worker_id);\n",
    "                            result_tx_clone.send(ResultMessage::WorkerFinished(worker_id)).unwrap();\n",
    "                            break;\n",
    "                        }\n",
    "                        Err(_) => {\n",
    "                            println!(\"Worker {} channel closed\", worker_id);\n",
    "                            break;\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            });\n",
    "            \n",
    "            worker_handles.push(handle);\n",
    "        }\n",
    "        \n",
    "        // Send work to workers\n",
    "        for url in urls {\n",
    "            work_tx.send(WorkerMessage::Scrape(url)).unwrap();\n",
    "        }\n",
    "        \n",
    "        // Send shutdown messages\n",
    "        for _ in 0..self.worker_count {\n",
    "            work_tx.send(WorkerMessage::Shutdown).unwrap();\n",
    "        }\n",
    "        \n",
    "        drop(work_tx); // Close the channel\n",
    "        \n",
    "        // Collect results\n",
    "        let mut finished_workers = 0;\n",
    "        \n",
    "        for result in result_rx {\n",
    "            match result {\n",
    "                ResultMessage::Success(page) => {\n",
    "                    println!(\"‚úÖ Scraped: {} ({} words, {}ms)\", \n",
    "                            page.url, page.word_count, page.load_time_ms);\n",
    "                    \n",
    "                    self.results.lock().unwrap().push(page);\n",
    "                    \n",
    "                    // Update stats\n",
    "                    let mut stats = self.stats.lock().unwrap();\n",
    "                    *stats.entry(\"successful_scrapes\".to_string()).or_insert(0) += 1;\n",
    "                }\n",
    "                ResultMessage::Error(url, error) => {\n",
    "                    println!(\"‚ùå Error scraping {}: {}\", url, error);\n",
    "                    self.errors.lock().unwrap().push((url, error));\n",
    "                    \n",
    "                    // Update stats\n",
    "                    let mut stats = self.stats.lock().unwrap();\n",
    "                    *stats.entry(\"failed_scrapes\".to_string()).or_insert(0) += 1;\n",
    "                }\n",
    "                ResultMessage::WorkerFinished(worker_id) => {\n",
    "                    println!(\"Worker {} finished\", worker_id);\n",
    "                    finished_workers += 1;\n",
    "                    \n",
    "                    if finished_workers == self.worker_count {\n",
    "                        break;\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        // Wait for all workers to complete\n",
    "        for handle in worker_handles {\n",
    "            handle.join().unwrap();\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    fn print_summary(&self) {\n",
    "        let results = self.results.lock().unwrap();\n",
    "        let errors = self.errors.lock().unwrap();\n",
    "        let stats = self.stats.lock().unwrap();\n",
    "        \n",
    "        println!(\"\\nüìä Scraping Summary:\");\n",
    "        println!(\"  Successful scrapes: {}\", results.len());\n",
    "        println!(\"  Failed scrapes: {}\", errors.len());\n",
    "        \n",
    "        if !results.is_empty() {\n",
    "            let total_words: usize = results.iter().map(|p| p.word_count).sum();\n",
    "            let avg_words = total_words / results.len();\n",
    "            let total_time: u64 = results.iter().map(|p| p.load_time_ms).sum();\n",
    "            let avg_time = total_time / results.len() as u64;\n",
    "            \n",
    "            println!(\"  Average words per page: {}\", avg_words);\n",
    "            println!(\"  Average load time: {}ms\", avg_time);\n",
    "        }\n",
    "        \n",
    "        if !errors.is_empty() {\n",
    "            println!(\"\\n‚ùå Errors:\");\n",
    "            for (url, error) in errors.iter() {\n",
    "                println!(\"  {}: {}\", url, error);\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        println!(\"\\nüìà Detailed Stats: {:?}\", *stats);\n",
    "    }\n",
    "}\n",
    "\n",
    "fn web_scraper_demo() {\n",
    "    println!(\"\\n=== Concurrent Web Scraper Demo ===\");\n",
    "    \n",
    "    let scraper = WebScraper::new(3); // 3 worker threads\n",
    "    \n",
    "    let urls = vec![\n",
    "        \"https://example.com\".to_string(),\n",
    "        \"https://rust-lang.org\".to_string(),\n",
    "        \"https://github.com\".to_string(),\n",
    "        \"https://stackoverflow.com\".to_string(),\n",
    "        \"https://error-site.com\".to_string(), // This will simulate an error\n",
    "        \"https://docs.rs\".to_string(),\n",
    "        \"https://crates.io\".to_string(),\n",
    "        \"https://another-error.com\".to_string(), // Another error\n",
    "    ];\n",
    "    \n",
    "    println!(\"Starting concurrent scraping of {} URLs with {} workers...\", \n",
    "            urls.len(), scraper.worker_count);\n",
    "    \n",
    "    let start_time = std::time::Instant::now();\n",
    "    scraper.scrape_urls(urls);\n",
    "    let elapsed = start_time.elapsed();\n",
    "    \n",
    "    scraper.print_summary();\n",
    "    println!(\"\\n‚è±Ô∏è  Total execution time: {:?}\", elapsed);\n",
    "}\n",
    "\n",
    "web_scraper_demo();"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "// Basic async functions and futures\n",
    "// Note: This is conceptual code for learning - evcxr doesn't support async runtimes\n",
    "\n",
    "use std::future::Future;\n",
    "use std::pin::Pin;\n",
    "use std::task::{Context, Poll};\n",
    "use std::time::{Duration, Instant};\n",
    "\n",
    "// Simple async function\n",
    "async fn simple_async_function() -> String {\n",
    "    \"Hello from async function!\".to_string()\n",
    "}\n",
    "\n",
    "// Async function with delay simulation\n",
    "async fn delayed_computation(delay_ms: u64, value: i32) -> i32 {\n",
    "    // In real async code, this would be:\n",
    "    // tokio::time::sleep(Duration::from_millis(delay_ms)).await;\n",
    "    \n",
    "    println!(\"Starting computation with {}ms delay for value {}\", delay_ms, value);\n",
    "    \n",
    "    // Simulate async work\n",
    "    value * 2\n",
    "}\n",
    "\n",
    "// Custom Future implementation\n",
    "struct DelayedValue {\n",
    "    value: i32,\n",
    "    delay: Duration,\n",
    "    start_time: Option<Instant>,\n",
    "}\n",
    "\n",
    "impl DelayedValue {\n",
    "    fn new(value: i32, delay: Duration) -> Self {\n",
    "        DelayedValue {\n",
    "            value,\n",
    "            delay,\n",
    "            start_time: None,\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "impl Future for DelayedValue {\n",
    "    type Output = i32;\n",
    "    \n",
    "    fn poll(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Self::Output> {\n",
    "        let start_time = self.start_time.get_or_insert_with(Instant::now);\n",
    "        \n",
    "        if start_time.elapsed() >= self.delay {\n",
    "            println!(\"DelayedValue ready: {}\", self.value);\n",
    "            Poll::Ready(self.value)\n",
    "        } else {\n",
    "            // In a real runtime, we'd register a waker\n",
    "            cx.waker().wake_by_ref();\n",
    "            Poll::Pending\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "// Async error handling\n",
    "#[derive(Debug)]\n",
    "enum AsyncError {\n",
    "    NetworkError(String),\n",
    "    TimeoutError,\n",
    "    ParseError(String),\n",
    "}\n",
    "\n",
    "impl std::fmt::Display for AsyncError {\n",
    "    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n",
    "        match self {\n",
    "            AsyncError::NetworkError(msg) => write!(f, \"Network error: {}\", msg),\n",
    "            AsyncError::TimeoutError => write!(f, \"Operation timed out\"),\n",
    "            AsyncError::ParseError(msg) => write!(f, \"Parse error: {}\", msg),\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "impl std::error::Error for AsyncError {}\n",
    "\n",
    "// Async function with error handling\n",
    "async fn fetch_data(url: &str) -> Result<String, AsyncError> {\n",
    "    println!(\"Fetching data from: {}\", url);\n",
    "    \n",
    "    // Simulate different outcomes\n",
    "    if url.contains(\"error\") {\n",
    "        Err(AsyncError::NetworkError(\"Connection failed\".to_string()))\n",
    "    } else if url.contains(\"timeout\") {\n",
    "        Err(AsyncError::TimeoutError)\n",
    "    } else {\n",
    "        Ok(format!(\"Data from {}\", url))\n",
    "    }\n",
    "}\n",
    "\n",
    "// Combining multiple async operations\n",
    "async fn process_multiple_urls(urls: Vec<&str>) -> Vec<Result<String, AsyncError>> {\n",
    "    let mut results = Vec::new();\n",
    "    \n",
    "    for url in urls {\n",
    "        let result = fetch_data(url).await;\n",
    "        results.push(result);\n",
    "    }\n",
    "    \n",
    "    results\n",
    "}\n",
    "\n",
    "fn async_concepts_demo() {\n",
    "    println!(\"=== Async Programming Concepts ===\");\n",
    "    \n",
    "    // Note: In a real async environment, you would use:\n",
    "    // #[tokio::main]\n",
    "    // async fn main() {\n",
    "    //     let result = simple_async_function().await;\n",
    "    //     println!(\"Result: {}\", result);\n",
    "    // }\n",
    "    \n",
    "    println!(\"Async function concepts:\");\n",
    "    println!(\"- async fn returns impl Future<Output = T>\");\n",
    "    println!(\"- .await suspends execution until Future is ready\");\n",
    "    println!(\"- Futures are lazy - they don't run until awaited\");\n",
    "    println!(\"- Runtime manages task scheduling and I/O\");\n",
    "    \n",
    "    // Demonstrate Future trait concepts\n",
    "    println!(\"\\nCustom Future implementation:\");\n",
    "    let delayed = DelayedValue::new(42, Duration::from_millis(100));\n",
    "    println!(\"Created DelayedValue future (not yet executed)\");\n",
    "    \n",
    "    // Error handling patterns\n",
    "    println!(\"\\nAsync error handling patterns:\");\n",
    "    println!(\"- Use Result<T, E> for fallible operations\");\n",
    "    println!(\"- ? operator works with async functions\");\n",
    "    println!(\"- Combine with try_join! for concurrent error handling\");\n",
    "}\n",
    "\n",
    "async_concepts_demo();"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "// Async patterns and combinators (conceptual)\n",
    "\n",
    "use std::collections::HashMap;\n",
    "\n",
    "// Async data structures\n",
    "#[derive(Debug, Clone)]\n",
    "struct AsyncTask {\n",
    "    id: u32,\n",
    "    name: String,\n",
    "    duration_ms: u64,\n",
    "    dependencies: Vec<u32>,\n",
    "}\n",
    "\n",
    "impl AsyncTask {\n",
    "    fn new(id: u32, name: String, duration_ms: u64) -> Self {\n",
    "        AsyncTask {\n",
    "            id,\n",
    "            name,\n",
    "            duration_ms,\n",
    "            dependencies: Vec::new(),\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    fn with_dependencies(mut self, deps: Vec<u32>) -> Self {\n",
    "        self.dependencies = deps;\n",
    "        self\n",
    "    }\n",
    "}\n",
    "\n",
    "// Async task executor (conceptual)\n",
    "struct AsyncTaskExecutor {\n",
    "    tasks: HashMap<u32, AsyncTask>,\n",
    "    completed: HashMap<u32, String>,\n",
    "}\n",
    "\n",
    "impl AsyncTaskExecutor {\n",
    "    fn new() -> Self {\n",
    "        AsyncTaskExecutor {\n",
    "            tasks: HashMap::new(),\n",
    "            completed: HashMap::new(),\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    fn add_task(&mut self, task: AsyncTask) {\n",
    "        self.tasks.insert(task.id, task);\n",
    "    }\n",
    "    \n",
    "    // Simulate async task execution\n",
    "    async fn execute_task(&mut self, task_id: u32) -> Result<String, String> {\n",
    "        let task = self.tasks.get(&task_id)\n",
    "            .ok_or_else(|| format!(\"Task {} not found\", task_id))?;\n",
    "        \n",
    "        // Check dependencies\n",
    "        for dep_id in &task.dependencies {\n",
    "            if !self.completed.contains_key(dep_id) {\n",
    "                return Err(format!(\"Dependency {} not completed for task {}\", dep_id, task_id));\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        println!(\"Executing task {}: {} ({}ms)\", task.id, task.name, task.duration_ms);\n",
    "        \n",
    "        // In real async code:\n",
    "        // tokio::time::sleep(Duration::from_millis(task.duration_ms)).await;\n",
    "        \n",
    "        let result = format!(\"Completed: {}\", task.name);\n",
    "        self.completed.insert(task_id, result.clone());\n",
    "        \n",
    "        Ok(result)\n",
    "    }\n",
    "    \n",
    "    // Execute all tasks respecting dependencies\n",
    "    async fn execute_all(&mut self) -> Vec<Result<String, String>> {\n",
    "        let mut results = Vec::new();\n",
    "        let task_ids: Vec<u32> = self.tasks.keys().cloned().collect();\n",
    "        \n",
    "        // Simple sequential execution (in real code, use proper dependency resolution)\n",
    "        for task_id in task_ids {\n",
    "            let result = self.execute_task(task_id).await;\n",
    "            results.push(result);\n",
    "        }\n",
    "        \n",
    "        results\n",
    "    }\n",
    "}\n",
    "\n",
    "// Async stream processing (conceptual)\n",
    "struct AsyncDataProcessor {\n",
    "    name: String,\n",
    "}\n",
    "\n",
    "impl AsyncDataProcessor {\n",
    "    fn new(name: String) -> Self {\n",
    "        AsyncDataProcessor { name }\n",
    "    }\n",
    "    \n",
    "    // Process data asynchronously\n",
    "    async fn process_item(&self, item: i32) -> Result<i32, String> {\n",
    "        println!(\"{}: Processing item {}\", self.name, item);\n",
    "        \n",
    "        // Simulate processing time and potential errors\n",
    "        if item < 0 {\n",
    "            Err(format!(\"Invalid item: {}\", item))\n",
    "        } else {\n",
    "            Ok(item * 2)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // Process multiple items\n",
    "    async fn process_batch(&self, items: Vec<i32>) -> Vec<Result<i32, String>> {\n",
    "        let mut results = Vec::new();\n",
    "        \n",
    "        for item in items {\n",
    "            let result = self.process_item(item).await;\n",
    "            results.push(result);\n",
    "        }\n",
    "        \n",
    "        results\n",
    "    }\n",
    "    \n",
    "    // Concurrent processing (conceptual)\n",
    "    async fn process_concurrent(&self, items: Vec<i32>) -> Vec<Result<i32, String>> {\n",
    "        println!(\"{}: Starting concurrent processing of {} items\", self.name, items.len());\n",
    "        \n",
    "        // In real async code with tokio:\n",
    "        // let futures: Vec<_> = items.into_iter()\n",
    "        //     .map(|item| self.process_item(item))\n",
    "        //     .collect();\n",
    "        // \n",
    "        // futures::future::join_all(futures).await\n",
    "        \n",
    "        // For demonstration, process sequentially\n",
    "        self.process_batch(items).await\n",
    "    }\n",
    "}\n",
    "\n",
    "// Async HTTP client simulation\n",
    "struct AsyncHttpClient {\n",
    "    base_url: String,\n",
    "    timeout_ms: u64,\n",
    "}\n",
    "\n",
    "impl AsyncHttpClient {\n",
    "    fn new(base_url: String, timeout_ms: u64) -> Self {\n",
    "        AsyncHttpClient { base_url, timeout_ms }\n",
    "    }\n",
    "    \n",
    "    async fn get(&self, path: &str) -> Result<String, AsyncError> {\n",
    "        let url = format!(\"{}/{}\", self.base_url, path);\n",
    "        println!(\"GET {}\", url);\n",
    "        \n",
    "        // Simulate network request\n",
    "        if path.contains(\"slow\") {\n",
    "            // Simulate timeout\n",
    "            Err(AsyncError::TimeoutError)\n",
    "        } else if path.contains(\"error\") {\n",
    "            Err(AsyncError::NetworkError(\"404 Not Found\".to_string()))\n",
    "        } else {\n",
    "            Ok(format!(\"Response from {}\", url))\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    async fn post(&self, path: &str, data: &str) -> Result<String, AsyncError> {\n",
    "        let url = format!(\"{}/{}\", self.base_url, path);\n",
    "        println!(\"POST {} with data: {}\", url, data);\n",
    "        \n",
    "        // Simulate POST request\n",
    "        Ok(format!(\"Posted to {}: {}\", url, data))\n",
    "    }\n",
    "    \n",
    "    // Batch requests\n",
    "    async fn batch_get(&self, paths: Vec<&str>) -> Vec<Result<String, AsyncError>> {\n",
    "        let mut results = Vec::new();\n",
    "        \n",
    "        for path in paths {\n",
    "            let result = self.get(path).await;\n",
    "            results.push(result);\n",
    "        }\n",
    "        \n",
    "        results\n",
    "    }\n",
    "}\n",
    "\n",
    "fn async_patterns_demo() {\n",
    "    println!(\"\\n=== Async Patterns and Combinators ===\");\n",
    "    \n",
    "    // Task execution patterns\n",
    "    println!(\"Async task execution patterns:\");\n",
    "    println!(\"- Sequential: await each task in order\");\n",
    "    println!(\"- Concurrent: join_all for parallel execution\");\n",
    "    println!(\"- Racing: select! for first completion\");\n",
    "    println!(\"- Streaming: process data as it arrives\");\n",
    "    \n",
    "    // Error handling patterns\n",
    "    println!(\"\\nAsync error handling:\");\n",
    "    println!(\"- try_join! fails fast on first error\");\n",
    "    println!(\"- join_all collects all results\");\n",
    "    println!(\"- timeout() adds time limits\");\n",
    "    println!(\"- retry() for resilient operations\");\n",
    "    \n",
    "    // Common async patterns\n",
    "    println!(\"\\nCommon async patterns:\");\n",
    "    println!(\"- Producer/Consumer with async channels\");\n",
    "    println!(\"- Connection pooling for resources\");\n",
    "    println!(\"- Circuit breaker for fault tolerance\");\n",
    "    println!(\"- Rate limiting for API calls\");\n",
    "    \n",
    "    // Performance considerations\n",
    "    println!(\"\\nPerformance considerations:\");\n",
    "    println!(\"- Async is great for I/O-bound tasks\");\n",
    "    println!(\"- Use threads for CPU-intensive work\");\n",
    "    println!(\"- Avoid blocking operations in async code\");\n",
    "    println!(\"- Consider task spawning overhead\");\n",
    "}\n",
    "\n",
    "async_patterns_demo();"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "// TODO: Complete the async web service simulation\n",
    "\n",
    "use std::collections::HashMap;\n",
    "use std::time::{Duration, Instant};\n",
    "\n",
    "#[derive(Debug, Clone)]\n",
    "struct Request {\n",
    "    id: u32,\n",
    "    method: String,\n",
    "    path: String,\n",
    "    body: Option<String>,\n",
    "    timestamp: Instant,\n",
    "}\n",
    "\n",
    "impl Request {\n",
    "    fn new(id: u32, method: String, path: String) -> Self {\n",
    "        Request {\n",
    "            id,\n",
    "            method,\n",
    "            path,\n",
    "            body: None,\n",
    "            timestamp: Instant::now(),\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    fn with_body(mut self, body: String) -> Self {\n",
    "        self.body = Some(body);\n",
    "        self\n",
    "    }\n",
    "}\n",
    "\n",
    "#[derive(Debug, Clone)]\n",
    "struct Response {\n",
    "    status: u16,\n",
    "    body: String,\n",
    "    processing_time_ms: u64,\n",
    "}\n",
    "\n",
    "impl Response {\n",
    "    fn ok(body: String, processing_time_ms: u64) -> Self {\n",
    "        Response {\n",
    "            status: 200,\n",
    "            body,\n",
    "            processing_time_ms,\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    fn not_found(processing_time_ms: u64) -> Self {\n",
    "        Response {\n",
    "            status: 404,\n",
    "            body: \"Not Found\".to_string(),\n",
    "            processing_time_ms,\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    fn error(message: String, processing_time_ms: u64) -> Self {\n",
    "        Response {\n",
    "            status: 500,\n",
    "            body: message,\n",
    "            processing_time_ms,\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "// Async web service\n",
    "struct AsyncWebService {\n",
    "    name: String,\n",
    "    data_store: HashMap<String, String>,\n",
    "    request_count: u32,\n",
    "}\n",
    "\n",
    "impl AsyncWebService {\n",
    "    fn new(name: String) -> Self {\n",
    "        let mut data_store = HashMap::new();\n",
    "        data_store.insert(\"users/1\".to_string(), \"User 1 Data\".to_string());\n",
    "        data_store.insert(\"users/2\".to_string(), \"User 2 Data\".to_string());\n",
    "        data_store.insert(\"posts/1\".to_string(), \"Post 1 Content\".to_string());\n",
    "        \n",
    "        AsyncWebService {\n",
    "            name,\n",
    "            data_store,\n",
    "            request_count: 0,\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // Handle GET requests\n",
    "    async fn handle_get(&mut self, path: &str) -> Response {\n",
    "        let start_time = Instant::now();\n",
    "        \n",
    "        println!(\"{}: Handling GET {}\", self.name, path);\n",
    "        \n",
    "        // Simulate processing time based on path\n",
    "        let processing_delay = match path {\n",
    "            p if p.contains(\"slow\") => 200,\n",
    "            p if p.contains(\"users\") => 50,\n",
    "            p if p.contains(\"posts\") => 30,\n",
    "            _ => 10,\n",
    "        };\n",
    "        \n",
    "        // In real async code: tokio::time::sleep(Duration::from_millis(processing_delay)).await;\n",
    "        \n",
    "        let processing_time = start_time.elapsed().as_millis() as u64 + processing_delay;\n",
    "        \n",
    "        // Simulate different responses\n",
    "        if path.contains(\"error\") {\n",
    "            Response::error(\"Internal Server Error\".to_string(), processing_time)\n",
    "        } else if let Some(data) = self.data_store.get(path) {\n",
    "            Response::ok(data.clone(), processing_time)\n",
    "        } else {\n",
    "            Response::not_found(processing_time)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // Handle POST requests\n",
    "    async fn handle_post(&mut self, path: &str, body: &str) -> Response {\n",
    "        let start_time = Instant::now();\n",
    "        \n",
    "        println!(\"{}: Handling POST {} with body: {}\", self.name, path, body);\n",
    "        \n",
    "        // Simulate processing\n",
    "        let processing_delay = 100; // POST operations are typically slower\n",
    "        let processing_time = start_time.elapsed().as_millis() as u64 + processing_delay;\n",
    "        \n",
    "        if path.contains(\"error\") {\n",
    "            Response::error(\"Failed to create resource\".to_string(), processing_time)\n",
    "        } else {\n",
    "            // Store the data\n",
    "            self.data_store.insert(path.to_string(), body.to_string());\n",
    "            Response::ok(format!(\"Created resource at {}\", path), processing_time)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // Main request handler\n",
    "    async fn handle_request(&mut self, request: Request) -> Response {\n",
    "        self.request_count += 1;\n",
    "        \n",
    "        println!(\"\\n[Request {}] {} {} (ID: {})\", \n",
    "                self.request_count, request.method, request.path, request.id);\n",
    "        \n",
    "        let response = match request.method.as_str() {\n",
    "            \"GET\" => self.handle_get(&request.path).await,\n",
    "            \"POST\" => {\n",
    "                let body = request.body.as_deref().unwrap_or(\"\");\n",
    "                self.handle_post(&request.path, body).await\n",
    "            }\n",
    "            _ => Response::error(\"Method not allowed\".to_string(), 1),\n",
    "        };\n",
    "        \n",
    "        println!(\"[Response {}] Status: {}, Time: {}ms\", \n",
    "                request.id, response.status, response.processing_time_ms);\n",
    "        \n",
    "        response\n",
    "    }\n",
    "    \n",
    "    // Process multiple requests\n",
    "    async fn process_requests(&mut self, requests: Vec<Request>) -> Vec<Response> {\n",
    "        let mut responses = Vec::new();\n",
    "        \n",
    "        println!(\"\\nüöÄ Processing {} requests...\", requests.len());\n",
    "        \n",
    "        for request in requests {\n",
    "            let response = self.handle_request(request).await;\n",
    "            responses.push(response);\n",
    "        }\n",
    "        \n",
    "        responses\n",
    "    }\n",
    "    \n",
    "    // Concurrent request processing (conceptual)\n",
    "    async fn process_concurrent(&mut self, requests: Vec<Request>) -> Vec<Response> {\n",
    "        println!(\"\\n‚ö° Processing {} requests concurrently...\", requests.len());\n",
    "        \n",
    "        // In real async code with proper concurrency:\n",
    "        // let futures: Vec<_> = requests.into_iter()\n",
    "        //     .map(|req| self.handle_request(req))\n",
    "        //     .collect();\n",
    "        // futures::future::join_all(futures).await\n",
    "        \n",
    "        // For demonstration, process sequentially\n",
    "        self.process_requests(requests).await\n",
    "    }\n",
    "    \n",
    "    fn print_stats(&self, responses: &[Response]) {\n",
    "        let total_requests = responses.len();\n",
    "        let successful = responses.iter().filter(|r| r.status == 200).count();\n",
    "        let errors = responses.iter().filter(|r| r.status >= 400).count();\n",
    "        \n",
    "        let total_time: u64 = responses.iter().map(|r| r.processing_time_ms).sum();\n",
    "        let avg_time = if total_requests > 0 { total_time / total_requests as u64 } else { 0 };\n",
    "        \n",
    "        println!(\"\\nüìä Service Statistics:\");\n",
    "        println!(\"  Total requests: {}\", total_requests);\n",
    "        println!(\"  Successful: {} ({:.1}%)\", successful, \n",
    "                (successful as f64 / total_requests as f64) * 100.0);\n",
    "        println!(\"  Errors: {} ({:.1}%)\", errors, \n",
    "                (errors as f64 / total_requests as f64) * 100.0);\n",
    "        println!(\"  Average response time: {}ms\", avg_time);\n",
    "        println!(\"  Total processing time: {}ms\", total_time);\n",
    "        println!(\"  Data store entries: {}\", self.data_store.len());\n",
    "    }\n",
    "}\n",
    "\n",
    "// Load balancer simulation\n",
    "struct AsyncLoadBalancer {\n",
    "    services: Vec<AsyncWebService>,\n",
    "    current_service: usize,\n",
    "}\n",
    "\n",
    "impl AsyncLoadBalancer {\n",
    "    fn new(service_names: Vec<String>) -> Self {\n",
    "        let services = service_names.into_iter()\n",
    "            .map(AsyncWebService::new)\n",
    "            .collect();\n",
    "        \n",
    "        AsyncLoadBalancer {\n",
    "            services,\n",
    "            current_service: 0,\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    // Round-robin load balancing\n",
    "    async fn handle_request(&mut self, request: Request) -> Response {\n",
    "        let service_index = self.current_service;\n",
    "        self.current_service = (self.current_service + 1) % self.services.len();\n",
    "        \n",
    "        println!(\"üîÑ Load balancer routing request {} to service {}\", \n",
    "                request.id, service_index);\n",
    "        \n",
    "        self.services[service_index].handle_request(request).await\n",
    "    }\n",
    "    \n",
    "    async fn process_requests(&mut self, requests: Vec<Request>) -> Vec<Response> {\n",
    "        let mut responses = Vec::new();\n",
    "        \n",
    "        for request in requests {\n",
    "            let response = self.handle_request(request).await;\n",
    "            responses.push(response);\n",
    "        }\n",
    "        \n",
    "        responses\n",
    "    }\n",
    "}\n",
    "\n",
    "fn async_web_service_demo() {\n",
    "    println!(\"\\n=== Async Web Service Simulation ===\");\n",
    "    \n",
    "    // Create requests\n",
    "    let requests = vec![\n",
    "        Request::new(1, \"GET\".to_string(), \"users/1\".to_string()),\n",
    "        Request::new(2, \"GET\".to_string(), \"users/2\".to_string()),\n",
    "        Request::new(3, \"POST\".to_string(), \"users/3\".to_string())\n",
    "            .with_body(\"New User Data\".to_string()),\n",
    "        Request::new(4, \"GET\".to_string(), \"posts/1\".to_string()),\n",
    "        Request::new(5, \"GET\".to_string(), \"nonexistent\".to_string()),\n",
    "        Request::new(6, \"GET\".to_string(), \"error-endpoint\".to_string()),\n",
    "        Request::new(7, \"GET\".to_string(), \"slow-endpoint\".to_string()),\n",
    "        Request::new(8, \"POST\".to_string(), \"posts/2\".to_string())\n",
    "            .with_body(\"New Post Content\".to_string()),\n",
    "    ];\n",
    "    \n",
    "    println!(\"Created {} test requests\", requests.len());\n",
    "    \n",
    "    // Note: In a real async environment, you would run this with:\n",
    "    // let mut service = AsyncWebService::new(\"TestService\".to_string());\n",
    "    // let responses = service.process_requests(requests).await;\n",
    "    // service.print_stats(&responses);\n",
    "    \n",
    "    println!(\"\\nüí° In a real async environment, this would:\");\n",
    "    println!(\"  - Process requests concurrently\");\n",
    "    println!(\"  - Use actual async I/O operations\");\n",
    "    println!(\"  - Handle thousands of concurrent connections\");\n",
    "    println!(\"  - Provide much better performance than blocking I/O\");\n",
    "    \n",
    "    println!(\"\\nüîß Key async patterns demonstrated:\");\n",
    "    println!(\"  - Async functions with .await\");\n",
    "    println!(\"  - Error handling with Result types\");\n",
    "    println!(\"  - State management in async contexts\");\n",
    "    println!(\"  - Request/response patterns\");\n",
    "    println!(\"  - Load balancing and service distribution\");\n",
    "}\n",
    "\n",
    "async_web_service_demo();"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Common Pitfalls: Concurrency\n",
    "\n",
    "### 1. Data Races with Shared Mutable State\n",
    "```rust\n",
    "use std::thread;\n",
    "\n",
    "let mut counter = 0;\n",
    "let handle = thread::spawn(|| {\n",
    "    counter += 1;  // ‚ùå Error: can't capture mutable reference across threads\n",
    "});\n",
    "```\n",
    "**Solution:** Use `Arc<Mutex<T>>` for shared mutable state:\n",
    "```rust\n",
    "use std::sync::{Arc, Mutex};\n",
    "\n",
    "let counter = Arc::new(Mutex::new(0));\n",
    "let counter_clone = Arc::clone(&counter);\n",
    "let handle = thread::spawn(move || {\n",
    "    let mut num = counter_clone.lock().unwrap();\n",
    "    *num += 1;\n",
    "});\n",
    "```\n",
    "\n",
    "### 2. Deadlocks from Lock Ordering\n",
    "```rust\n",
    "use std::sync::Mutex;\n",
    "\n",
    "let lock_a = Mutex::new(1);\n",
    "let lock_b = Mutex::new(2);\n",
    "\n",
    "// Thread 1: locks A then B\n",
    "thread::spawn(|| {\n",
    "    let a = lock_a.lock().unwrap();\n",
    "    let b = lock_b.lock().unwrap();  // ‚ùå Potential deadlock\n",
    "});\n",
    "\n",
    "// Thread 2: locks B then A\n",
    "thread::spawn(|| {\n",
    "    let b = lock_b.lock().unwrap();\n",
    "    let a = lock_a.lock().unwrap();  // ‚ùå Potential deadlock\n",
    "});\n",
    "```\n",
    "**Solution:** Always acquire locks in the same order across all threads\n",
    "\n",
    "### 3. Forgetting to Join Threads\n",
    "```rust\n",
    "thread::spawn(|| {\n",
    "    println!(\"Important work!\");\n",
    "});  // ‚ùå Thread may not complete before main exits\n",
    "```\n",
    "**Solution:** Store handle and join:\n",
    "```rust\n",
    "let handle = thread::spawn(|| {\n",
    "    println!(\"Important work!\");\n",
    "});\n",
    "handle.join().unwrap();  // ‚úÖ Wait for completion\n",
    "```\n",
    "\n",
    "### 4. Channel Sender/Receiver Lifetime Issues\n",
    "```rust\n",
    "use std::sync::mpsc;\n",
    "\n",
    "let (tx, rx) = mpsc::channel();\n",
    "drop(tx);  // Drop sender\n",
    "rx.recv();  // ‚ùå Error: all senders disconnected\n",
    "```\n",
    "**Solution:** Keep senders alive while receivers are waiting\n",
    "\n",
    "### 5. Blocking in Async Context\n",
    "```rust\n",
    "async fn bad_async() {\n",
    "    std::thread::sleep(Duration::from_secs(1));  // ‚ùå Blocks executor thread!\n",
    "}\n",
    "```\n",
    "**Solution:** Use async sleep:\n",
    "```rust\n",
    "async fn good_async() {\n",
    "    tokio::time::sleep(Duration::from_secs(1)).await;  // ‚úÖ Yields to executor\n",
    "}\n",
    "```\n",
    "\n",
    "### 6. Not Handling Panics in Threads\n",
    "```rust\n",
    "let handle = thread::spawn(|| {\n",
    "    panic!(\"Thread panic!\");\n",
    "});\n",
    "// Main thread continues...\n",
    "handle.join().unwrap();  // ‚ùå Panic propagates here\n",
    "```\n",
    "**Solution:** Handle join result:\n",
    "```rust\n",
    "match handle.join() {\n",
    "    Ok(_) => println!(\"Thread completed\"),\n",
    "    Err(e) => println!(\"Thread panicked: {:?}\", e),\n",
    "}\n",
    "```\n",
    "\n",
    "### 7. Send/Sync Trait Violations\n",
    "```rust\n",
    "use std::rc::Rc;\n",
    "\n",
    "let rc = Rc::new(5);\n",
    "thread::spawn(move || {\n",
    "    println!(\"{}\", rc);  // ‚ùå Error: Rc is not Send\n",
    "});\n",
    "```\n",
    "**Solution:** Use thread-safe types:\n",
    "- `Rc<T>` ‚Üí `Arc<T>` (Send + Sync)\n",
    "- `RefCell<T>` ‚Üí `Mutex<T>` or `RwLock<T>`\n",
    "\n",
    "### 8. Forgetting .await in Async Functions\n",
    "```rust\n",
    "async fn fetch_data() -> String {\n",
    "    // ...\n",
    "}\n",
    "\n",
    "async fn process() {\n",
    "    let data = fetch_data();  // ‚ùå Returns Future, doesn't execute\n",
    "    println!(\"{}\", data);  // Error: Future doesn't implement Display\n",
    "}\n",
    "```\n",
    "**Solution:** Always .await async calls:\n",
    "```rust\n",
    "async fn process() {\n",
    "    let data = fetch_data().await;  // ‚úÖ Executes and waits\n",
    "    println!(\"{}\", data);\n",
    "}\n",
    "```\n",
    "\n",
    "### 9. Mutex Poisoning\n",
    "```rust\n",
    "let mutex = Arc::new(Mutex::new(0));\n",
    "let mutex_clone = Arc::clone(&mutex);\n",
    "\n",
    "thread::spawn(move || {\n",
    "    let mut data = mutex_clone.lock().unwrap();\n",
    "    *data += 1;\n",
    "    panic!(\"Oops!\");  // Mutex becomes poisoned\n",
    "});\n",
    "\n",
    "// Later...\n",
    "let data = mutex.lock().unwrap();  // ‚ùå Panic: mutex poisoned\n",
    "```\n",
    "**Solution:** Handle poisoned mutex:\n",
    "```rust\n",
    "match mutex.lock() {\n",
    "    Ok(guard) => { /* use guard */ },\n",
    "    Err(poisoned) => {\n",
    "        let guard = poisoned.into_inner();  // Recover data\n",
    "        // Handle poisoned state\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "### 10. Race Conditions with Channels\n",
    "```rust\n",
    "let (tx, rx) = mpsc::channel();\n",
    "\n",
    "thread::spawn(move || {\n",
    "    tx.send(1).unwrap();\n",
    "    tx.send(2).unwrap();\n",
    "});\n",
    "\n",
    "// ‚ö†Ô∏è Order not guaranteed in complex scenarios\n",
    "println!(\"{}\", rx.recv().unwrap());\n",
    "```\n",
    "**Note:** Messages arrive in order from single sender, but multiple senders may interleave\n",
    "\n",
    "**üìö Rust Book References:**\n",
    "- [Chapter 16 - Fearless Concurrency](https://doc.rust-lang.org/book/ch16-00-concurrency.html)\n",
    "- [Chapter 16.1 - Using Threads](https://doc.rust-lang.org/book/ch16-01-threads.html)\n",
    "- [Chapter 16.2 - Message Passing](https://doc.rust-lang.org/book/ch16-02-message-passing.html)\n",
    "- [Chapter 16.3 - Shared-State Concurrency](https://doc.rust-lang.org/book/ch16-03-shared-state.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rust",
   "language": "rust",
   "name": "rust"
  },
  "language_info": {
   "codemirror_mode": "rust",
   "file_extension": ".rs",
   "mimetype": "text/rust",
   "name": "Rust",
   "pygment_lexer": "rust",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
